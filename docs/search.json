[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDA of Behavioral Risk Analysis of Nutrition, Physical Health and Obesity",
    "section": "",
    "text": "1 Introduction"
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\n\n\nCode\ndf &lt;- read.csv('data.csv')\n\n\n\n\nCode\n#dim(df)\n\n\nDimensions:- 88629 - rows 33 - columns\n\n\nCode\n#str(df)\n\n\nThe data can actually be divided into different questions and its supporting variables.\ne.g “Question: Percent of adults who engage in no leisure-time physical activity?” will have a numerical value which is actually a percentage. It will be shown that this answer belongs to which Class of question, location of the respondents as well as a category. This category column makes this data very interesting in the sense of how it is saved. For most of the question - topic - location combination, there exists multiple categories like RACE, Education, Income, etc as well as the values of the categories apart from the answer to the question. Due to this, a lot of columns like Education, Gender, Income has values which are missing when the Stratification category don’t correspond to that particular category value. It is actually better if we drop these particular columns when doing the analysis since they don’t really add a lot."
  },
  {
    "objectID": "data.html#data-cleaning",
    "href": "data.html#data-cleaning",
    "title": "2  Data",
    "section": "2.2 Data Cleaning",
    "text": "2.2 Data Cleaning\nLets look at each and every column in the dataframe and see how relevant they are. We will try to transform/drop them if we see it to be relevant to be dropped.\n\n\nCode\nhead(df,n=5)\n\n\n  YearStart YearEnd LocationAbbr LocationDesc\n1      2020    2020           US     National\n2      2014    2014           GU         Guam\n3      2013    2013           US     National\n4      2013    2013           US     National\n5      2015    2015           US     National\n                                  Datasource                   Class\n1 Behavioral Risk Factor Surveillance System       Physical Activity\n2 Behavioral Risk Factor Surveillance System Obesity / Weight Status\n3 Behavioral Risk Factor Surveillance System Obesity / Weight Status\n4 Behavioral Risk Factor Surveillance System Obesity / Weight Status\n5 Behavioral Risk Factor Surveillance System       Physical Activity\n                         Topic\n1 Physical Activity - Behavior\n2      Obesity / Weight Status\n3      Obesity / Weight Status\n4      Obesity / Weight Status\n5 Physical Activity - Behavior\n                                                                                                                                                                                               Question\n1                                                                                                                                     Percent of adults who engage in no leisure-time physical activity\n2                                                                                                                                            Percent of adults aged 18 years and older who have obesity\n3                                                                                                                                            Percent of adults aged 18 years and older who have obesity\n4                                                                                                                       Percent of adults aged 18 years and older who have an overweight classification\n5 Percent of adults who achieve at least 300 minutes a week of moderate-intensity aerobic physical activity or 150 minutes a week of vigorous-intensity aerobic activity (or an equivalent combination)\n  Data_Value_Unit Data_Value_Type Data_Value Data_Value_Alt\n1              NA           Value       30.6           30.6\n2              NA           Value       29.3           29.3\n3              NA           Value       28.8           28.8\n4              NA           Value       32.7           32.7\n5              NA           Value       26.6           26.6\n  Data_Value_Footnote_Symbol Data_Value_Footnote Low_Confidence_Limit\n1                                                                29.4\n2                                                                25.7\n3                                                                28.1\n4                                                                31.9\n5                                                                25.6\n  High_Confidence_Limit Sample_Size Total Age.years.            Education\n1                  31.8       31255                                      \n2                  33.3         842                  High school graduate\n3                  29.5       62562                                      \n4                  33.5       60069                                      \n5                  27.6       30904                                      \n  Gender            Income Race.Ethnicity             GeoLocation ClassID\n1                                Hispanic                              PA\n2                                         (13.444304, 144.793731)     OWS\n3        $50,000 - $74,999                                            OWS\n4        Data not reported                                            OWS\n5        Less than $15,000                                             PA\n  TopicID QuestionID DataValueTypeID LocationID StratificationCategory1\n1     PA1       Q047           VALUE         59          Race/Ethnicity\n2    OWS1       Q036           VALUE         66               Education\n3    OWS1       Q036           VALUE         59                  Income\n4    OWS1       Q037           VALUE         59                  Income\n5     PA1       Q045           VALUE         59                  Income\n       Stratification1 StratificationCategoryId1 StratificationID1\n1             Hispanic                      RACE           RACEHIS\n2 High school graduate                       EDU         EDUHSGRAD\n3    $50,000 - $74,999                       INC           INC5075\n4    Data not reported                       INC             INCNR\n5    Less than $15,000                       INC         INCLESS15\n\n\nDropping - YearEnd (same values), Datasource, Topic is same as class, Data_Value_Unit has only null values, drop ALT- same values, drop Data_Value_Type, Confidence Limits dropping for now,\n\n\nCode\n# Check if Column1 and Column2 have the same values\nsame_values &lt;- all(df$YearStart == df$YearEnd)\n\n# Print the result\nif (same_values) {\n  print(\"Column1 and Column2 have the same values.\")\n} else {\n  print(\"Column1 and Column2 have different values.\")\n}\n\n\n[1] \"Column1 and Column2 have the same values.\"\n\n\nIn our data, YearStart and YearEnd have the same values. So it doesn’t make sense for us to keep both of them together. Hence, we will be looking to drop YearEnd.\nWe are going to keep LocationAbbr since we might use them to make Geographic Location based visualization in the future.\nWe will be dropping LocationDesc, since LocationAbbr can act as a proxy for LocationDesc and we don’t need to keep both of them together.\n\n\nCode\nunique(df$Datasource)\n\n\n[1] \"Behavioral Risk Factor Surveillance System\"\n\n\nWe will be dropping Datasource since it has only one unique value and doesn’t add anything to the data.\n\n\nCode\nunique(df$Class)\n\n\n[1] \"Physical Activity\"       \"Obesity / Weight Status\"\n[3] \"Fruits and Vegetables\"  \n\n\nWe will keep Class as it acts like a categorization of different Surveillance metrics.\n\n\nCode\nunique(df$Topic)\n\n\n[1] \"Physical Activity - Behavior\"     \"Obesity / Weight Status\"         \n[3] \"Fruits and Vegetables - Behavior\"\n\n\nWe are going to drop Topic since it has a one to one correspondence with Class. Therefore, we don’t need to keep more Class and Topic.\nQuestion is one of our most important columns, so naturally we aren’t planning to drop that particular column.\n\n\nCode\nunique(df$Data_Value_Unit)\n\n\n[1] NA\n\n\n\n\nCode\nunique(df$Data_Value_Type)\n\n\n[1] \"Value\"\n\n\nData_Value_Unit and Data_Value_Type have only a singular unique value in the column, hence we can drop both of them.\n\n\nCode\n# Check if Column1 and Column2 have the same values\n\nsame_values &lt;- all(ifelse(is.na(df$Data_Value), -99, df$Data_Value) == ifelse(is.na(df$Data_Value_Alt), -99, df$Data_Value_Alt))\n\n# Print the result\nif (same_values) {\n  print(\"Column1 and Column2 have the same values.\")\n} else {\n  print(\"Column1 and Column2 have different values.\")\n}\n\n\n[1] \"Column1 and Column2 have the same values.\"\n\n\nData_Value and Data_Value_Alt have the same values across all the rows. We can keep Data_Value and drop Data_Value_Alt from our dataframe.\n\n\nCode\nunique(df$Data_Value_Footnote_Symbol)\n\n\n[1] \"\"  \"~\"\n\n\nData_Value_Footnote_Symbol doesn’t have any values of importance so we can drop that column.\n\n\nCode\nunique(df$Data_Value_Footnote)\n\n\n[1] \"\"                                                       \n[2] \"Data not available because sample size is insufficient.\"\n\n\nWe can drop since Data_Value_Footnote since it is purely correlated to the fact whether the Data_Value field is NA or not. In the case where it is NA, it has the value “Data not available because sample size is insufficient.”. Hence, we should keep in mind that wherever Data_Value field is NA, it is due to the lack of sample size.\nWe are going to drop Low_Confidence_Limit and High_Confidence_Limit, since we are not going to use their fields in our analysis.\nWe are going to keep Sample_Size since it might be useful for us inorder to perform visualizations.\nWe are going to drop Total,Age.years,Education,Gender,Income,Race.Ethnicity since they are perfectly correlated with StratificationCategory1 and Stratification1.\nColumns below can also be dropped since columns for their proxy already exist which we are planning to keep. ClassID TopicID QuestionID DataValueTypeID LocationID StratificationCategoryId1 StratificationID1\n\n\nCode\ndf &lt;- subset(df, select = -c(YearEnd, Datasource,LocationDesc, Topic,Data_Value_Unit,Data_Value_Type,Data_Value_Alt,Data_Value_Footnote_Symbol,Data_Value_Footnote,Low_Confidence_Limit,High_Confidence_Limit,Total,Age.years.,Education,Gender,Income,Race.Ethnicity,ClassID,TopicID,QuestionID,DataValueTypeID,LocationID ,StratificationCategoryId1,StratificationID1))"
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\n\n\nCode\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(tidyverse)\nlibrary(redav)\n\nset.seed(5702)\n\n\n\n\nCode\n## Setting all the blank values to NA values so that we can do the missing value analysis properly\n\n#df[df['StratificationCategory1']=='','StratificationCategory1'] = NA\n#df[df['Stratification1']=='','Stratification1'] = NA\n#df[df['GeoLocation']=='','GeoLocation'] = NA\n\n# Convert blank values to NA\ndf &lt;- df %&gt;%\n  mutate_if(is.character, na_if, \"\")\n\n\nNow that we have chosen the important columns, we are going to rename to columns.\nLocationAbbr -&gt; Location Data_Value -&gt; Value Sample_Size] -&gt; SampleSize StratificationCategory1 -&gt; Category Stratification1 -&gt; CategoryVal\n\n\nCode\ncolnames(df)[2] &lt;-  \"Location\"\ncolnames(df)[5] &lt;-  \"Value\"\ncolnames(df)[6] &lt;-  \"SampleSize\"\ncolnames(df)[8] &lt;-  \"Category\"\ncolnames(df)[9] &lt;-  \"CategoryVal\"\n\n\n\n\nCode\n# Calculate percentage of missing rows for each column\nmissing_percentage &lt;- colMeans(is.na(df)) * 100\n\n# Create a bar chart\nggplot(data.frame(variable = names(missing_percentage), missing_percentage),\n       aes(x = reorder(variable, missing_percentage), y = missing_percentage)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", width = 0.5) +\n  labs(x = \"Variable\", y = \"Percentage of Missing Rows\") +\n  theme_minimal() +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 10))\n\n\n\n\n\n\n\nCode\nplot_missing(df, percent = TRUE)\n\n\n\n\n\nFrom the missing value plots we can find a lot of insights.\n\nFrom the graph it seems like only Value, SampleSize and GeoLocation have missing values.\nOut of all the rows, around 88% seems to have columns with no missing data. Rest of the rows seem to have at least one column with missing values.\nAccording to the missing patterns, there are 4 different patterns available. The first pattern is where we have all the rows completely filled. The second pattern has Value and SampleSize missing. The third pattern has only the GeoLocation missing. The fourth pattern has Value, SampleSize, Category and CategoryValue missing.\nThere is a correlation between the missing SampleSize rows and Value rows. There are also a correlation between the missing Category and CategoryValues.\nFrom the initial data cleaning, we know that this is due to the fact that there rows have an insufficient sample size. Due to this insufficiency, both the Value and SampleSize field are NULLs together. After a quick check, we can decipher that this indeed is true.\nRegarding pattern 4, it is not sure why these particular columns (i.e Category and CategoryValue) are NULL for some certain rows but since they are NULL only when Pattern 2 exists, i.e lack of sufficient sample size, we can choose to combine it with pattern 2 for all intents and purposes.\nThe interesting case here is the pattern 3 since this missing data is not due to the lack of sufficient sample size. After a quick analysis, we can see that this corresponds to the Location value as ‘US’. This makes a lot of sense since, US itself doesn’t have a GeoLocation value but it’s internal states do have a GeoLocation value. Hence we need to keep this in mind which doing analysis for the entire Country as a whole rather than State wise analysis.\n\nConclusions:-\n\nWe can drop rows belonging to pattern 2 and pattern 4 since due to the lack of sufficient SampleSize, we don’t have values to actually derive insights from.\nWe cannot drop rows belonging to pattern 3 since they correspond to the entire US Data as a whole."
  }
]